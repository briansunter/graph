public:: true
date:: 2022-12-09
categories:: [[programming]] [[ai]]
tags:: [[ai]] [[programming]]
description:: Best resources for machine learning
coverimage:: /assets/1071614177.01._SCLZZZZZZZ_SX500_1670647404075_0.jpg

- # Overview
	- I'm very eager to get into Artificial Intelligence (AI), but with so much to learn, I'm not sure where to start. Do I need a lot of math? What kind? Which areas should I focus on? How can I make sense of all the topics? What tools should I use? Additionally, how is the field developing, and what direction is it headed in?
	- I'm a software engineer with some math under my belt, and my goal is to gain a thorough understanding of AI so I can apply it to my work. I'm particularly interested in generative AI, natural language processing, and building intelligent agents. I also want to gain the necessary math skills to have a strong understanding of the fundamentals, but I don't want to too bogged down in some of the advanced mathematical details.
	- To help me on this journey, I've collected and summarized the best courses and books to help me get started on the right foot
	- I plan to study some of the following AI learning resources and this site will be a record of my successes and failures. I hope you'll join me on this journey as I learn more about this ever-evolving field.
- ![Screenshot 2022-12-13 at 9.27.53 PM.png](../assets/Screenshot_2022-12-13_at_9.27.53_PM_1671002890776_0.png)
- # [Deeplearning AI Intro Course](https://www.coursera.org/specializations/machine-learning-introduction)
	- Introductory course by Andrew Ng covering practical machine learning topics using Python
	- Time: 2.5 months (5 hours/week)
	- ## Topics
		- ### Supervised learning
			- linear regression
			- logistic regression
			- neural networks
			- decision trees
				- Tree Ensembles
		- ### Unsupervised learning
			- clustering
			- dimensionality reduction
			- recommender systems
			- anomaly detection
		- ### Tools
			- Python
				- numpy
				- scikit learn
			- Tensorflow
			- XGBoost
		- ### Best Practices
			- Regularization to Avoid Overfitting
			- evaluating and tuning models
			- improving performance
- # Deeplearning.ai Deep Learning Course
	- [Course Link](https://www.deeplearning.ai/courses/deep-learning-specialization/)
	- Practical intermediate deep learning course by Andrew Ng
	- ## Topics
		- Tensorflow
		- Artificial Neural Networks
		- Convolutional Neural Networks
		- Recurrent Neural Networks
		- Transformers
		- Python Programming
		- Deep Learning
		- Backpropagation
		- Optimization
		- Hyperparameter Tuning
		- Machine Learning
		- Transfer Learning
		- Multi-Task Learning
		- Object Detection and Segmentation
		- Facial Recognition System
		- Gated Recurrent Unit (GRU)
		- Long Short Term Memory (LSTM)
		- Attention Models
		- Natural Language Processing
- # Practical Deep Learning Fast.ai
	- A free course designed for people with some coding experience, who want to learn how to apply deep learning and machine learning to practical problems.
	- [Course Link](https://course.fast.ai/)
	- ## Topics
		- Deployment
		- Neural net foundations
		- Natural Language (NLP)
		- From-scratch model
		- Random forests
		- Collaborative filtering
		- Convolutions (CNNs)
- # Deeplearning.ai Natural Language Course
	- [Course Link](https://www.deeplearning.ai/courses/natural-language-processing-specialization/)
	- how to design NLP applications that perform question-answering and sentiment analysis, create tools to translate languages, summarize text, and even build chatbots.
	- Time: 4 months (6 hours/week)
	- ## Topics
		- Sentiment Analysis
		- Transformers
		- Attention Models
		- Machine Translation
		- Word2vec
		- Word Embeddings
		- Locality-Sensitive Hashing
		- Vector Space Models
		- Parts-of-Speech Tagging
		- N-gram Language Models
		- Autocorrect
		- Sentiment with Neural Networks
		- Siamese Networks
		- Natural Language Generation
		- Named Entity Recognition (NER)
		- Reformer Models
		- Neural Machine Translation
		- Chatbots
		- T5 + BERT Models
- # Deeplearning.io Tensorflow Data and Deployment Course
	- [Course Link](https://www.deeplearning.ai/courses/tensorflow-data-and-deployment-specialization/)
	- Learn how to get your machine learning models into the hands of real people on all kinds of devices. Start by understanding how to train and run machine learning models in browsers and in mobile applications. Learn how to leverage built-in datasets with just a few lines of code, learn about data pipelines with TensorFlow data services, use APIs to control data splitting, process all types of unstructured data and retrain deployed models with user data while maintaining data privacy. Apply
	- Time: 4 months (3 hours/week)
	- ## Topics
		- Tensorflow
		- Object Detection
		- JavaScript
		- Convolutional Neural Network
		- Tensorflow.js
		- Tensorflow Lite
		- Mathematical Optimization
		- Extraction, Transformation And Loading (ETL)
		- Data Pipelines
- # Deeplearning.io Generative Adversarial Networks Course
	- [Course Link](https://www.deeplearning.ai/courses/generative-adversarial-networks-gans-specialization/)
	- Introduction to image generation with GANs, charting a path from foundational concepts to advanced techniques through an easy-to-understand approach.
	- Time: 3 months (8 hours/week)
	- ## Topics
		- Generator
		- Image-to-Image Translation
		- Glossary of Computer Graphics
		- Discriminator
		- Generative Adversarial Networks
		- Controllable Generation
		- WGANs
		- Conditional Generation
		- Components of GANs
		- DCGANs
		- Bias in GANs
		- StyleGANs
- # Deeplearning.io Tensorflow Advanced
	- [Course Link](https://www.deeplearning.ai/courses/tensorflow-advanced-techniques-specialization/)
	- Expand your knowledge of the Functional API and build exotic non-sequential model types. You will learn how to optimize training in different environments with multiple processors and chip types and get introduced to advanced computer vision scenarios such as object detection, image segmentation, and interpreting convolutions. You will also explore generative deep learning including the ways AIs can create new content from Style Transfer to Auto Encoding, VAEs, and GANs.
	- Time: 5 months (6 hours/week)
	- ## Topics
		- Model Interpretability
		- Custom Training Loops
		- Custom and Exotic Models
		- Generative Machine Learning
		- Object Detection
		- Functional API
		- Custom Layers
		- Custom and Exotic Models with Functional API
		- Custom Loss Functions
		- Distribution Strategies
		- Basic Tensor Functionality
		- GradientTape for Optimization
- # Deeplearning.io MLOps Course
	- [Course Link](https://www.deeplearning.ai/courses/machine-learning-engineering-for-production-mlops/)
	- How to conceptualize, build, and maintain integrated systems that continuously operate in production.
	- Time: 4 months (5 hours/week)
	- ## Topics
		- Data Pipelines
		- Model Pipelines
		- Deploy Pipelines
		- Managing Machine Learning Production systems
		- ML Deployment Challenges
		- Project Scoping and Design
		- Concept Drift
		- Model Baseline
		- Human-level Performance (HLP)
		- TensorFlow Extended (TFX)
		- ML Metadata
		- Data transformation
		- Data augmentation
		- Data validation
		- AutoML
		- Precomputing predictions
		- Fairness Indicators
		- Explainable AI
		- Model Performance Analysis
		- TensorFlow Serving
		- Model Monitoring
		- General Data Protection Regulation (GDPR)
		- Model Registries
- # Deeplearning.io Data Science on AWS Course
	- [Course Link](https://www.deeplearning.ai/courses/practical-data-science-specialization/)
	- Develop the practical skills to effectively deploy your data science projects and overcome challenges at each step of the ML workflow using Amazon SageMaker.
	- Time: 3 months (5 hours/week)
	- ## Topics
		- Automated Machine Learning (AutoML)
		- Natural Language Processing with BERT
		- ML Pipelines and ML Operations (MLOps)
		- A/B Testing, Model Deployment, and Monitoring
		- Data Labeling at Scale
		- Data Ingestion
		- Exploratory Data Analysis
		- Statistical Data Bias Detection
		- Multi-class Classification with FastText and BlazingText
		- Feature Engineering and Feature Store
		- Model Training, Tuning, and Deployment with BERT
		- Model Debugging, Profiling, and Evaluation
		- ML Pipelines and MLOps
		- Artifact and Lineage Tracking
		- Distributed Model Training and Hyperparameter Tuning
		- Cost Savings and Performance Improvements
		- Human-in-the-Loop Pipelines
- # Huggingface Course
	- {{youtube https://youtu.be/00GKzGyWFEs}}
	- [Course Link](https://huggingface.co/course/chapter1/1)
	- This course will teach you about natural language processing (NLP) using libraries from the Hugging Face ecosystem â€” ðŸ¤— Transformers, ðŸ¤— Datasets, ðŸ¤— Tokenizers, and ðŸ¤— Accelerate â€” as well as the Hugging Face Hub.
	- ## Topics
		- Transformer Models
		- Fine-tuning a pretrained model
		- Sharing models and tokenizers
		- Datasets library
		- Tokenizers Library
		- Building and sharing demos
		- Optimizing for production
- # Huggingface Diffusion Models Class
	- ![hfdiffusion.png](../assets/hfdiffusion_1670997592570_0.png)
	- [Course Link](https://github.com/huggingface/diffusion-models-class)
	- ðŸ‘©â€ðŸŽ“Â Study the theory behind diffusion models
	- ðŸ§¨Â Learn how to generate images and audio with the popularÂ ðŸ¤—Â Diffusers library
	- ðŸ‹ï¸â€â™‚ï¸Â Train your own diffusion models from scratch
	- ðŸ“»Â Fine-tune existing diffusion models on new datasets
	- ðŸ—ºÂ Explore conditional generation and guidance
	- ðŸ§‘â€ðŸ”¬Â Create your own custom diffusion model pipelines
	- ## Topics
		- pytorch
		- difussers and diffusion models
		- Fine tuning
		- Stable Difussion
- # Huggingface Deep Reinforcement Learning Course
	- ![thumbnail.jpg](../assets/thumbnail_1670996834646_0.jpg)
	- [Course Link](https://github.com/huggingface/deep-rl-class)
	- ðŸ“– Study Deep Reinforcement Learning inÂ **theory and practice.**
	- ðŸ§‘â€ðŸ’» Learn toÂ **use famous Deep RL libraries**Â such asÂ [Stable Baselines3](https://stable-baselines3.readthedocs.io/en/master/),Â [RL Baselines3 Zoo](https://github.com/DLR-RM/rl-baselines3-zoo),Â [Sample Factory](https://samplefactory.dev/)Â andÂ [CleanRL](https://github.com/vwxyzjn/cleanrl).
	- ðŸ¤–Â **Train agents in unique environments**Â such asÂ [SnowballFight](https://huggingface.co/spaces/ThomasSimonini/SnowballFight),Â [Huggy the Doggo ðŸ¶](https://huggingface.co/spaces/ThomasSimonini/Huggy),Â [MineRL (MinecraftÂ â›ï¸)](https://minerl.io/),Â [VizDoom (Doom)](https://vizdoom.cs.put.edu.pl/)Â and classical ones such asÂ [Space Invaders](https://www.gymlibrary.dev/environments/atari/)Â andÂ [PyBullet](https://pybullet.org/wordpress/).
	- ðŸ’¾ Share yourÂ **trained agents with one line of code to the Hub**Â and also download powerful agents from the community.
	- ðŸ† Participate in challenges where you willÂ **evaluate your agents against other teams. Youâ€™ll also get to play against the agents youâ€™ll train.**
	- ## Topics
		- Q-Learning
		- Policy Gradient with PyTorch
		- Actor Critic Methods
		- Proximal Policy Optimization
		- Multi-Agents
		- Decision Transformers
		- offline Reinforcement Learning
- # Andrej Karpathy Neural Networks Zero to Hero Course
	- {{youtube https://youtu.be/VMj-3S1tku0}}
	- This is the most step-by-step spelled-out explanation of backpropagation and training of neural networks. It only assumes basic knowledge of Python and a vague recollection of calculus from high school.
	- ### Topics
		- backpropagation
		- pytorch
		- multi-layer perceptron
		- loss function
		- gradient descent optimization
		- bigrams
		- vector normalization
		- tensor broadcasting
		- model smoothing
		- one-hot encodings
		- vectorized loss
		- embeddings
		- hidden layers
		- negative log likelihood loss
		- cross entropy
		- overfitting
		- learning rate
		- character embeddings
		- sampling from models
		- Google colab
		- TanH activation function
		- batch normalization
		- forward pass activation statistics
		- backward pass gradient
		- kaiming init
		- parameter activation
		- gradient statistics
		- batchnorm
- # 3blue1brown YouTube courses
	- ## Neural Networks from the Ground Up
		- The basics of neural networks, and the math behind how they learn
		- {{youtube https://youtu.be/aircAruvnKk}}
		- ### Topics
			- Neural Networks
			- Gradient Descent
			- Backpropagation
	- ## Essence of Linear Algebra
		- An introduction to visualizing what matrices are really doing
		- {{youtube https://youtu.be/fNk_zzaMoSs}}
		- ### Topics
			- Vectors
			- Linear Combinations
			- Span
			- Basis Vectors
			- Linear Transformation
			- Matrices
			- Matrix Multiplication
			- Three dimensional linear transformations
			- Determinant
			- Inverse Matrices
				- Column Space
				- Null Space
			- Nonsquare Matrices
			- Dot Product
			- Duality
			- Cross Products
			- Cramer's Rule
			- Change of basis
			- Eigenvectors and Eigenvalues
			- Abstract Vector spaces
		- ## Essence of Calculus
			- Visual introductions to the core ideas of derivatives, integrals, limits and more
			- {{youtube https://youtu.be/WUvTyaaNkzM}}
			- ### Topics
				- Derivative
				- Chain Rule
				- Product Rule
				- Euler's Number
				- Implicit Differentiation
				- Limits
				- L'HÃ´pital's rule
				- Epsilon Delta
				- Integration
				- Fundamental Theorem of Calculus
				- Higher Order Derivatives
				- Taylor Series
	- ## Probability
		- An assortment of introductory ideas in probability
		- {{youtube https://youtu.be/HZGCoVF3YvM}}
		- ### Topics
			- Bayes Theorem
			- Binomial Distribution
			- Probability Density Functions
# Hands-On Machine Learning with Scikit-Learn and TensorFlow
	- By using concrete examples, minimal theory, and two production-ready Python frameworksâ€”scikit-learn and TensorFlow you gain an intuitive understanding of the concepts and tools for building intelligent systems. Youâ€™ll learn simple linear regression and progressing to deep neural networks. With exercises in each chapter to help you apply what youâ€™ve learned, all you need is programming experience to get started.
	- [Book Link](https://a.co/d/fOBe9wy)
	- ## Topics
		- Types of Machine Learning Systems
		- Supervised/Unsupervised Learning
		- Batch and Online Learning
		- Instance-Based Versus Model-Based Learning
		- Challenges of Machine Learning
		- End-to-End Machine Learning Project
		- ### Classification
			- Binary Classifier
			- Performance Measures
				- Cross validation
				- confusion matrix
			- multiclass classification
		- ### Training Models
			- Linear Regressions
			- Gradient Descent
			- Polynomial Regression
			- Learning Curves
			- Regularized Linear Models
			- Logistic Regression
			- Support Vector Machines
				- Linear SVM Classification
					- Soft Margin Classification
				- Nonlinear SVM Classification
				- Decision Function and Predictions
				- Training Objective
				- Quadratic Programming
				- The Dual Problem
				- Kernelized SVMs
				- Online SVMs
		- ### Decision Trees
			- Ensemble Learning and Random Forests
				- Voting Classifiers
			- Bagging and Pasting
				- Bagging and Pasting in Scikit-Learn
				- Out-of-Bag Evaluation
			- Random Patches and Random Subspaces
			- Random Forests
			- Extra-Trees
			- Feature Importance
			- Boosting
				- AdaBoost
				- Gradient Boosting
			- ### Dimensionality Reduction
				- PCA
				- Projection
				- Manifold Learning
				- Kernel PCA
				- LLE
			- ### Unsupervised Learning
				- Clustering
				- Gaussian Mixtures
			- ### Introduction to Artificial Neural Networks with Keras
				- From Biological to Artificial Neurons
				- Implementing MLPs with Keras
				- Fine-Tuning Neural Network Hyperparameters
			- ### Training Deep Neural Networks
				- Vanishing/Exploding Gradients Problems
				- Reusing Pretrained Layers
				- Faster Optimizers
				- Avoiding Overfitting Through Regularization
			- ### Custom Models and Training with TensorFlow
				- Using TensorFlow like NumPy
				- Customizing Models and Training Algorithms
				- TensorFlow Functions and Graphs
			- ### Loading and Preprocessing Data with TensorFlow
				- Data API
				- TFRecord
				- Preprocessing the Input Features
				- TF Transform
			- ### Deep Computer Vision Using Convolutional Neural Networks
				- Convolutional Layers
				- Pooling Layers
				- CNN Architectures
				- Implementing a ResNet-34 CNN Using Keras
				- Object Detection
				- Semantic Segmentation
			- ### Processing Sequences Using RNNs and CNNs
				- Recurrent Neurons and Layers
				- Training RNNs
				- Forecasting a Time Series
				- Handling Long Sequences
			- ### Natural Language Processing with RNNs and Attention
				- Generating Shakespearean Text Using a Character RNN
				- Sentiment Analysis
				- An Encoderâ€“Decoder Network for Neural Machine Translation
				- Attention Mechanisms
					- Transformers
			- ### Representation Learning and Generative Learning Using Autoencoders and GANs
				- Stacked Autoencoders
				- Generative Adversarial Networks
			- ### Reinforcement Learning
				- Policy Search
				- Neural Network Policies
				- Policy Gradients
				- Q-Learning
				- TF-Agents Library
			- ### Training and Deploying TensorFlow Models at Scale
				- Serving a TensorFlow Model
				- Deploying a Model to a Mobile or Embedded Device
				- Training Models Across Multiple Devices
			-
			-
- # SQL for Data Analysis
	- ![714qourw99L.jpg](../assets/714qourw99L_1670744519576_0.jpg)
	- [Book Link](https://a.co/d/i0ZpwDy)
	- You'll learn how to use both common and exotic SQL functions such as joins, window functions, subqueries, and regular expressions in new, innovative ways--as well as how to combine SQL techniques to accomplish your goals faster, with understandable code.
	- ## Topics
		- Databases
		- Preparing Data for Analysis
			- Data cleaning
			- deduplication
			- nulls
			- shaping data
		- Time Series Data
			- Dates and time
			- Trends
			- Windows
			- Seasonality
		- Cohort Analysis
			- Retention
			- Related Cohort Analysis
			- Cross section analysis
		- Text Analysis
		- Anomaly Detection
		- Experiment Analysis
		- Complex Data Sets
# Practical Statistics for Data Scientists
	- ![149207294X.01._SCLZZZZZZZ_SX500_.jpg](../assets/149207294X.01._SCLZZZZZZZ_SX500_1670724734688_0.jpg)
	- [Book Link](https://a.co/d/69tMYZB)
	- Many data science resources incorporate statistical methods but lack a deeper statistical perspective. If youâ€™re familiar with the R or Python programming languages and have some exposure to statistics, this quick reference bridges the gap in an accessible, readable format.
		- ## Topics
			- Rectangular Data
				- Data Frames
			- Estimates
				- Mean, median, mode, variability, percentile
			- Distribution and sampling
				- bias, central limit theorem, standard error, resampling, confidence interval, normal distribution
				- normal, long tail, t, binomial, poisson, weibuill distributions
			- Statistical Experiments and Significance Testing
				- A/B testing, Hypothesis testing, null hypothesis
				- Pvalue, alpha, t-test, anova, chi-square, multi arm bandit
			- Regression and Prediction
				- Simple Linear regression
				- Multiple linear regression
				- Confidence and prediction intervals
			- Classification
				- naive bayes
				- discriminant analysis
				- logistic regression
				- imbalanced data
			- Statistical Machine Learning
				- knn
				- tree models
				- Bagging and Random Forest
				- Boosting
			- Unsupervised Learning
				- Principal Components Analysis
				- k-means clustering
				- hierarchal clustering
				- Model Clustering
				- Scaling and categorical variables
- # Essential Math for Data Science
	- ![81RiDmmmEBL.jpg](../assets/81RiDmmmEBL_1670724182934_0.jpg)
	- [Book Link](https://a.co/d/dWTNNj8)
	- Master the math needed to excel in data science, machine learning, and statistics. In this book author Thomas Nield guides you through areas like calculus, probability, linear algebra, and statistics
	- ## Topics
		- calculus
		- probability
		- linear algebra
			- vectors
			- matrices
			- matrix decomposition
		- statistics
			- p-values
			- statistical significance
		- linear regression
		- logistic regression
		- neural networks
		- SymPy
		- NumPy
		- scikit-learn
		- Data Science Career
# Data Science from Scratch
	- ![81SCVWF4A1L.jpg](../assets/81SCVWF4A1L_1670742445031_0.jpg)
	- [Book Link](https://a.co/d/ipkNz6T)
	- Get comfortable with the math and statistics at the core of data science, and with the hacking skills you need to get started as a data scientist. Packed with New material on deep learning, statistics, and natural language processing
	- ## Topics
		- Python
		- Matplotlib
		- Linear Algebra
			- Vectors
			- Matrices
		- Statistics
		- Probability
			- Bayes Theorem
			- Distribution
			- Central Limit Theorem
		- Hypothesis and Inference
			- p-value
			- confidence intervals
			- p-hacking
			- bayesian inference
		- Gradient Descent
		- Scraping Data
		- Working with Data
			- dataclasses
			- rescaling
			- cleaning
			- rescaling
			- dimensionality reduction
		- machine learning
			- modeling
			- overfitting
			- bias-variance
			- feature extraction
		- k-nearest neighbors
			- model
			- dimensionality
		- Naive Bayes
		- Simple Linear Regression
		- Mltiple Regression
		- Logistic Regression
		- Decision Tree
		- Neural Networks
		- Deep Learning
		- Clustering
		- Natural Language Processing
		- Network Analysis
			- eigenvector
			- directed graphs
		- Recommender Systems
			- Collaborative Filtering
			- Matrix Factorization
		- Databases and SQL
		- Mapreduce
		- Python
			- numpy
			- pandas
			- scikit-learn
			- visualization
	-
- # Practical Natural Language Processing
	- ![91pDCEA5uTL.jpg](../assets/91pDCEA5uTL_1670750101817_0.jpg)
	- [Book Link](https://a.co/d/8ogyjPZ)
	- This book gives a comprehensive view on building real world NLP applications. it covers the complete lifecycle of a typical NLP project - right from data collection to deploying and monitoring the model. Some of these steps are applicable to any ML pipeline while some are very specific to NLP. The book also introduces task-specific case studies and domain-specific guides to build an NLP system from scratch.
	- ## Topics
		- NLP: A Primer
		- NLP Pipeline
		- Text Representation
		- Text Classification
		- Information Extraction
		- Chatbots
		- Topics in Brief
		- Social Media
		- E-Commerce and Retail
		- Healthcare, Finance, and Law
		- The End-to-End NLP Process
# Deep Learning from Scratch
	- ![71vAAIa10YL.jpg](../assets/71vAAIa10YL_1670748325496_0.jpg)
	- [Book Link](https://www.amazon.com/Deep-Learning-Scratch-Building-Principles/dp/1492041416)
	- Shows you how neural networks work using a first principles approach. Youâ€™ll learn how to apply multilayer neural networks, convolutional neural networks, and recurrent neural networks from the ground up. With a thorough understanding of how neural networks work mathematically, computationally, and conceptually
	- ## Topics
		- Math Foundations
		- Fundamentals
		- Deep Learning from Scratch
		- Extensions
		- Convolutional Neural Networks
		- Recurrent Neural Networks
		- PyTorch
- # Generative Deep Learning by David Foster
	- ![71fGFYhl9WL.jpg](../assets/71fGFYhl9WL_1670829940119_0.jpg)
	- [Book Link](https://www.amazon.com/Generative-Deep-Learning-Teaching-Machines/dp/1492041947)
	- Discover how to re-create some of the most impressive examples of generative deep learning models, such as variational autoencoders, generative adversarial networks (GANs), encoder-decoder models, and world models.
	- ## Topics
		- Generative Versus Discriminative Modeling
		- Probabilistic Generative Models
		- Deep Neural Networks
		- Convolutional Layers
		- Batch Normalization
		- Dropout Layers
		- Autoencoders
		- Variational Autoencoder
		- Using VAEs to Generate Faces
		- Generative Adversarial Networks
		- Oscillating Loss
		- Mode Collapse
		- Uninformative Loss
		- Hyperparameters
		- Discrimators
		- Wasserstein GAN
		- CycleGAN
		- Neural Style Transfer
		- LSTM Network
		- Stacked Recurrent Networks
		- Gated Recurrent Units
		- Bidirectional Cells
		- Encoderâ€“Decoder Models
		- Music-Generating RNN
		- Reinforcement Learning
		- MDN-RNN
		- Controller Architecture
		- In-Dream Training
		- Transformer
		- ProGAN
		- Self-Attention GAN (SAGAN)
		- BigGAN
		- StyleGAN
- # Introducing MLOps
	- ![mlops.jpeg](../assets/mlops_1670830679583_0.jpeg)
	- [Book Link](https://www.amazon.com/Introducing-MLOps-Machine-Learning-Enterprise/dp/1492083291)
	- Introduces the key concepts of MLOps to help data scientists and application engineers not only operationalize ML models to drive real business change but also maintain and improve those models over time. Through lessons based on numerous MLOps applications around the world, nine experts in machine learning provide insights into the five steps of the model life cycle--Build, Preproduction, Deployment, Monitoring, and Governance
	- ## Topics
		- People of MLOps
		- Model Development
		- Data Sources and Exploratory Data Analysis
		- Feature Engineering and Selection
		- Training and Evaluation
		- Reproducibility
		- Productionalization and Deployment
		- Monitoring
		- Iteration and Life Cycle
		- Governance
		- Evaluating and Comparing Models
		- Adaptation from Development to Production Environments
		- Quality Assurance for Machine Learning
		- Reproducibility and Auditability
		- Machine Learning Security
		- Building ML Artifacts
		- Scaling Deployments
		- Model Degradation
		- Drift Detection in Practice
		- The Feedback Loop
		- The Feedback Loop
		- Model Governance
		- Responsible AI
		- MLOps in Practice
			- Consumer Credit Risk Management
			- Marketing Recommendation Engines
			- Consumption Forecast
- # Introduction to Statistical Learning
	- ![1071614177.01._SCLZZZZZZZ_SX500_.jpg](../assets/1071614177.01._SCLZZZZZZZ_SX500_1670647404075_0.jpg)
	- [Book link](https://www.amazon.com/Introduction-Statistical-Learning-Applications-Statistics-dp-1071614177/dp/1071614177/ref=dp_ob_title_bk)
	- [Site](https://www.statlearning.com/)
	- Accessible overview of the field of statistical learning, an essential toolset for making sense of the vast and complex data sets that have emerged in fields ranging from biology to finance to marketing to astrophysics in the past twenty years. This book presents some of the most important modeling and prediction techniques, along with relevant applications
	- This book is targeted at statisticians and non-statisticians alike who wish to use cutting-edge statistical learning techniques to analyze their data. The text assumes only a previous course in linear regression and no knowledge of matrix algebra.
	- Easier than **Elements of Statistical Learning**
	- ## Topics
		- linear regression
		- classification
		- resampling methods
		- shrinkage approaches
		- tree-based methods
		- support vector machines
		- clustering
		- deep learning
		- survival analysis
		- multiple testing
		- naÃ¯ve Bayes
		- generalized linear models
		- Bayesian additive regression trees
		- matrix completion
- # UC Berkeley CS188 Intro to AI
	- ![cs188_welcome.png](../assets/cs188_welcome_1671233486880_0.png)
	- This introductory Berkeley course accompanies the "Artificial Intelligence: A Modern Approach" book and provides lectures and course materials
	- [Course Link](http://ai.berkeley.edu/course_schedule.html)
	- ## Topics
		- Uninformed Search
		- A* Search and Heuristics
		- Constraint Satisfaction Problems
		- Game Trees
			- Minimax
			- Expectimax
		- Markov Decision Processes
		- Reinforcement Learning
		- Probability
		- Markov Models
		- Hidden Markov Models
		- Bayes' Nets
		- Decision Diagrams
		- Naive Bayes
		- Perceptrons
		- Kernels and Clustering
		- Advanced Applications: NLP, Games, Cars, Robotics, and Computer Vision
# Artificial Intelligence: A Modern Approach
	- ![513Hc42D83L.jpg](../assets/513Hc42D83L_1670836404894_0.jpg)
	- [Book Link](https://www.amazon.com/Artificial-Intelligence-Modern-Approach-3rd/dp/0136042597)
	- [Site Link](http://aima.cs.berkeley.edu/)
	- The de facto bible of artificial intelligence* It combines in-depth treatments of introductory and advanced concepts, along with historical background and accessible explanations. Including algorithms, code and pseudo-code, the book sits between master's and PhD
	- Focuses  on machine learning,Â deep learning, probabilistic programming, multiagent systems, and includes sections where the AI'sÂ utility functionÂ is uncertain, rather than certain.
	- ## Topics
		- Problem-solving
			- Searching
			- Adversarial Search and Games
			- Constraint Satisfaction Problems
		- Knowledge, reasoning, and planning
			- Logical Agents
			- First-Order Logic
			- Knowledge Representation
			- Automated Planning
		- Uncertain knowledge and reasoning
			- Probabilistic Reasoning
			- Decision Making
		- Machine Learning
			- Learning from Example
			- Learning Probabilistic Models
			- Deep Learning
			- Reinforcement Learning
		- Communicating, perceiving, and acting
			- Natural Language Processing
			- Deep Learning for NLP
			- Computer Vision
			- Robotics
# An Introduction to Probability and Inductive Logic
- ![0521775019.01._SCLZZZZZZZ_SX500_.jpg](../assets/0521775019.01._SCLZZZZZZZ_SX500_1671236538109_0.jpg)
- [Book Link](https://www.amazon.com/dp/0521775019?tag=bsunter06-20)
- Book focused on probability and logic from a philosophical rather than mathemetical perspective.
- The book has been designed to offer maximal accessibility to the widest range of students (not only those majoring in philosophy) and assumes no formal training in elementary symbolic logic. It offers a comprehensive course covering all basic definitions of induction and probability, and considers such topics as decision theory, Bayesianism, frequency ideas, and the philosophical problem of induction.
- # Probability for the Enthusiastic Beginner
	- ![61WkWvYJ9BL.jpg](../assets/61WkWvYJ9BL_1670723759360_0.jpg)
	- This book is a resource for high school and college students learning about probability for the first time. It covers all of the standard introductory topics, such as combinatorics, the rules of probability, Bayes' theorem, and expectation value, and includes 150 worked-out problems. Calculus is not required, although some problems involve it. It can be used as a main text or supplement in an introductory probability course.
	- [Book Link](https://www.amazon.com/Probability-Enthusiastic-Beginner-David-Morin/dp/1523318678)
	- ## Topics
		- Combinatorics
		- Bayes Theorem
		- Stirlingâ€™s Formula.
		- Expected values
		- variance
		- standard deviation
		- distributions
			- uniform
			- Bernoulli
			- binomial
			- exponential
			- Poisson
			- Gaussian
		- Gaussian approximations
		- law of large numbers
		- central limit theorem
		- Correlation and regression
- # Elements of Statistical Learning
	- ![CoverII_small.jpg](../assets/CoverII_small_1670721320001_0.jpg)
	- [Book Link](https://hastie.su.domains/ElemStatLearn/)
	- This book descibes the important ideas in  areas such as data mining, machine learning, and bioinformatics in a common conceptual framework. While the approach is statistical, the emphasis is on concepts rather than mathematics. Many examples are given, with a liberal use of color graphics. It should be a valuable resource for statisticians and anyone interested in data mining in science or industry.
	- ## Topics
		- Overview of supervised learning
		- Linear methods for regression
		- Linear methods for classification
		- Basis expansions and regularization
		- Kernel smoothing methods
		- Model assessment and selection
		- Model inference and averaging
		- Additive models, trees, and related methods
		- Boosting and additive trees
		- Neural networks
		- Support vector machines and flexible discriminants
		- Prototype methods and nearest-neighbors
		- Unsupervised learning
		- Random forests
		- Ensemble learning
		- Undirected graphical models
		- High-dimensional problems
- # Pattern Recognition and Machine Learning
	- ![61ECBlvkBCL._AC_SY780_.jpg](../assets/61ECBlvkBCL._AC_SY780_1670831683801_0.jpg)
	- The first textbook on pattern recognition to present the Bayesian viewpoint. The book presents approximate inference algorithms that permit fast approximate answers in situations where exact answers are not feasible. It uses graphical models to describe probability distributions when no other books apply graphical models to machine learning.
	- ## Topics
		- Probability Theory
		- Model Selection
		- The Curse of Dimensionality
		- Decision Theory
		- Information Theory
		- Probability Distributions
		- The Gaussian Distribution
		- Exponential Family
		- Nonparametric Methods
		- Linear Models for Regression
		- Linear Basis Function Models
		- Bayesian Linear Regression
		- Linear Models for Classification
			- Discriminant Functions
			- Probabilistic Generative Models
			- Probabilistic Discriminative Models
			- The Laplace Approximation
		- Neural Network
			- Feed-forward Network Functions
			- Network Training
			- Error Backpropagation
			- Hessian Matrix
			- Mixture Density Networks
			- Bayesian Neural Networks
		- Kernel Methods
			- Gaussian Processes
		- Sparse Kernel Machines
			- Maximum Margin Classifiers
			- Relevance Vector Machines
		- Graphical Models
			- Conditional Independence
			- Markov Random Fields
			- Inference in Graphical Models
		- Mixture Models and EM
			- K-means Clustering
			- Mixtures of Gaussians
		- Approximate Inference
			- Variational Inference
			- Variational Linear Regression
		- Sampling Methods
			- Basic Sampling Algorithms
			- Markov Chain Monte Carlo
			- Hybrid Monte Carlo Algorithm
		- Continuous Latent Variables
			- Principal Component Analysis
			- Probabilistic PCA
			- Kernel PCA
			- Nonlinear Latent Variable Models
		- Sequential Data
			- Markov Models
			- Hidden Markov Models
			- Linear Dynamical Systems
		- Combining Models
			- Bayesian Model Averaging
			- Committees
			- Boosting
			- Tree-based Models
			- Conditional Mixture Models
- # Deep Learning Goodfellow Book
	- ![61qbj4KwauL._SX258_BO1,204,203,200_.jpg](../assets/61qbj4KwauL._SX258_BO1,204,203,200_1670749190031_0.jpg)
	- The text offers mathematical and conceptual background, covering relevant concepts in linear algebra, probability theory and information theory, numerical computation, and machine learning. It describes deep learning techniques used by practitioners in industry, including deep feedforward networks, regularization, optimization algorithms, convolutional networks, sequence modeling, and practical methodology
	- [Book Link](https://www.deeplearningbook.org/)
	- ## Topics
		- Linear Algebra
		- Probability and Information Theory
		- Numerical Computation
		- Deep Feedforward Networks
		- Regularization for Deep Learning
		- Optimization for Training Deep Models
		  Gradient Descent and Structure of Neural Network Cost Functions
		- Tutorial on Optimization for Deep Networks
		- Batch Normalization
		- Convolutional Networks
		- Sequence Modeling: Recurrent and Recursive Networks
		- Linear Factors
		- Autoencoders
		- Representation Learning
		- Structured Probabilistic Models for Deep Learning
		- Monte Carlo Methods
		- Confronting the Partition Function
- # Reinforcement Learning: An Introduction
	- ![reinforcementlearning.jpg](../assets/reinforcementlearning_1670834056055_0.jpg)
	- [Book Link](https://www.amazon.com/Reinforcement-Learning-Introduction-Adaptive-Computation/dp/0262039249/ref=dp_ob_title_bk)
	- [Site Link](http://incompleteideas.net/book/the-book-2nd.html)
	- Part I covers as much of reinforcement learning as possible without going beyond the tabular case for which exact solutions can be found including UCB, Expected Sarsa, and Double Learning.
	- Part II extends these ideas to function approximation, such as artificial neural networks and the Fourier basis, and offers expanded treatment of off-policy learning and policy-gradient methods.
	- Part III has new chapters on reinforcement learning's relationships to psychology and neuroscience, as well as an updated case-studies chapter including AlphaGo and AlphaGo Zero, Atari game playing, and IBM Watson's wagering strategy.
	- The final chapter discusses the future societal impacts of reinforcement learning.
	- ## Topics
		- Tabular Solution Methods
			- Multi-arm Bandits
			- Finite Markov Decision Processes
			- Dynamic Programming
			- Monte Carlo Methods
			- Temporal-Difference Learning
			- Eligibility Traces
			- Planning and Learning with Tabular Methods
		- Approximate Solution Methods
			- On-policy Approximation of Action Values
			- Off-policy Approximation of Action Values
			- Policy Approximation
		- Psychology
		- Neuroscience
		- Applications and case studies
-
- # Papers
	- [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)
	- [Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift](https://arxiv.org/abs/1502.03167)
	- [Faster R-CNN: towards real-time object detection with region proposal networks](https://arxiv.org/abs/1506.01497)
	- [Neural Machine Translation by Jointly Learning to Align and Translate](https://arxiv.org/abs/1409.0473)
	- [Human-level control through deep reinforcement learning](https://www.nature.com/articles/nature14236)
	- [Mastering the game of Go with deep neural networks and tree search](https://www.nature.com/articles/nature16961)
	- [Unsupervised Representation Learning with Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434)
	- [Semi-Supervised Classification with Graph Convolutional Networks](https://arxiv.org/abs/1609.02907)
	- [Explaining and Harnessing Adversarial Examples](https://arxiv.org/abs/1412.6572)
	- [ImageNet Classification with Deep Convolutional Neural Networks(alexnet)](https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf)
	- [Deep Residual Learning for Image Recognition (resnet)](https://arxiv.org/abs/1512.03385v1)
	- [Attention Is All You Need (Transformers)](https://arxiv.org/abs/1706.03762)
- ## Mike Jordan Book list
	- Extremely rigorous books recommend by Mike Jordan from Berkeley intended for those focused on research. I will probably never read these and feels impossible to get through these in one lifetime.
	- [Hackernews Comment](https://news.ycombinator.com/item?id=1055389)
	- > Esentially all of the material in the following intermediate-level statistics book:
	- 1.) Casella, G. and Berger, R.L. (2001). "Statistical Inference" Duxbury Press.
	- > For a slightly more advanced book that's quite clear on mathematical techniques, the following book is quite good:
	- 2.) Ferguson, T. (1996). "A Course in Large Sample Theory" Chapman & Hall/CRC.
	- > You'll need to learn something about asymptotics at some point, and a good starting place is:
	- 3.) Lehmann, E. (2004). "Elements of Large-Sample Theory" Springer.
	- > Those are all frequentist books. You should also read something Bayesian:
	- 4.) Gelman, A. et al. (2003). "Bayesian Data Analysis" Chapman & Hall/CRC.
	- > you should start to read about Bayesian computation:
	- 5.) Robert, C. and Casella, G. (2005). "Monte Carlo Statistical Methods" Springer.
	- > On the probability front, a good intermediate text is:
	- 6.) Grimmett, G. and Stirzaker, D. (2001). "Probability and Random Processes" Oxford.
	- > At a more advanced level, a very good text is the following:
	- 7.) Pollard, D. (2001). "A User's Guide to Measure Theoretic Probability" Cambridge.
	- > The standard advanced textbook is Durrett, R. (2005). "Probability: Theory and Examples" Duxbury.
	- > Machine learning research also reposes on optimization theory. A good starting book on linear optimization that will prepare you for convex optimization:
	- 8.) Bertsimas, D. and Tsitsiklis, J. (1997). "Introduction to Linear Optimization" Athena.
	- > And then you can graduate to:
	- 9.) Boyd, S. and Vandenberghe, L. (2004). "Convex Optimization" Cambridge.
	- > Getting a full understanding of algorithmic linear algebra is also important. At some point you should feel familiar with most of the material in
	- 10.) Golub, G., and Van Loan, C. (1996). "Matrix Computations" Johns Hopkins.
	- > It's good to know some information theory. The classic is:
	- 11.) Cover, T. and Thomas, J. "Elements of Information Theory" Wiley.
	- > Finally, if you want to start to learn some more abstract math, you might want to start to learn some functional analysis (if you haven't already). Functional analysis is essentially linear algebra in infinite dimensions, and it's necessary for kernel methods, for nonparametric Bayesian methods, and for various other topics. Here's a book that I find very readable:
	- 12.) Kreyszig, E. (1989). "Introductory Functional Analysis with Applications" Wiley.
- # Other
	- [Superintelligence](https://www.amazon.com/Superintelligence-Dangers-Strategies-Nick-Bostrom-ebook/dp/B00LOOCGB2/ref=tmm_kin_swatch_0?_encoding=UTF8&qid=&sr=)
	- [Karpathy's CS231n: Convolutional Neural Networks for Visual Recognition](http://cs231n.stanford.edu/2016/)
	- [A First Course in Probability](https://www.amazon.com/First-Course-Probability-9th/dp/032179477X)
	- [Bayesian Reasoning and Machine Learning](http://web4.cs.ucl.ac.uk/staff/D.Barber/pmwiki/pmwiki.php?n=Brml.HomePage)
	- [Dive into Deep Learning](https://d2l.ai/)
	- [Principles of Mathematical Analysis by Walter Rudin](https://www.amazon.com/Principles-Mathematical-Analysis-International-Mathematics/dp/007054235X)
	- [Probability and Random Processes](https://www.amazon.com/Probability-Random-Processes-Geoffrey-Grimmett/dp/0198572220)
	- [Statistical Inference](https://www.amazon.com/Statistical-Inference-George-Casella/dp/0534243126)
	- [Think Stats](https://greenteapress.com/thinkstats/)
- # Overall Topics
  collapsed:: true
	- ## Tools
		- python
		- numpy
		- skikit-learn
		- matplotlib
		- jupyter
		- Google Colab
		- sql
		- tensorflow
		- pytorch
		- xgboost
		- huggingface
		- sagemaker
	- ## Supervised learning
		- linear regression
		- logistic regression
		- neural networks
		- decision trees
	- ## Unsupervised Learning
		- clustering
		- dimensionality reduction
		- reccomender systems
		- anomaly detection
	- ## Deep Learning
		- Artificial Neural Networks
			- Long Short Term Memory (LSTM)
		- Convolutional Neural Networks
		- Recurrent Neural Networks
			- Gated Recurrent Unit (GRU)
		- Transformers
		- Transfer Learning
		- Multi-Task Learning
		- ### Generative Adversarial Networks
			- Generator
			- Image-to-Image Translation
			- Discriminator
			- Controllable Generation
			- WGANs
			- Conditional Generation
			- DCGANs
			- StyleGANs
	- ## Natural Language Processing
		- Sentiment Analysis
		- Transformers
		- Attention Models
		- Machine Translation
		- Word2vec
		- Word Embeddings
		- Locality-Sensitive Hashing
		- Vector Space Models
		- Parts-of-Speech Tagging
		- N-gram Language Models
		- Autocorrect
		- Sentiment with Neural Networks
		- Siamese Networks
		- Natural Language Generation
		- Named Entity Recognition (NER)
		- Reformer Models
		- Neural Machine Translation
	- ## MLOps
		- Pipelines
			- Data
			- Model
			- Deploy
		- concept drift
		- Model Baseline
		- Data Transformation
		- Data Augmentation
		- Data Validation
		- AutoML
		- Explainability
		- Model Monitoring
		- Model Registries
		- A/B Testing
		- Data Ingestion
		- Data Labeling
		- Feature Engineering
		- Feature Store
		- Artifact and lineage tracking
		- Human-in-the-Loop Pipelines
		- Cost
		- Performance
		- Exploratory Data Analysis
	- ## Math
		- ### Linear Algebra
			- Vectors
			- Matrices
			- Determinant
			- Matrix Multiplication
			- Dot Product
			- Cross Product
			- Eigenvectors
			- Eigenvalues
		- ### Statistics
			- Estimates and approximation
			- Distribution
			- Sampling
			- Significance
			- Regression
			- Prediction
			- Bayes Theorem
			- support vector machines
		- ### Calculus
			- Limits
			- Derivative
			- Chain Rule
			- Product Rule
			- Euler's Number
			- Implicit Differentiation
			- L'HÃ´pital's rule
			- Epsilon Delta
			- Integration
			- Fundamental Theorem of Calculus
			- Higher Order Derivatives
			- Taylor Series